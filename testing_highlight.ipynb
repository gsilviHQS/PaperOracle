{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to highlight part of a pdf file, use the following command:\n",
    "# !python -m pip install --upgrade pymupdf\n",
    "import fitz\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import extract_all_text2\n",
    "import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tex = extract_all_text2('papers/2101.00689/Npi_paper.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEYS: dict_keys([])\n",
      "SECTIONS: dict_keys(['-', 'author', 'affiliation', 'title', 'date', 'abstract', 'Introduction', 'Gauge Ensemble', 'Interpolating Operators', 'Wick contractions', 'Spectra results', 'L{\\\\\"u}scher quantization conditions}\\n', 'Results for the scattering amplitudes', 'Parametrizations used', 'Fit procedure and results', 'Conclusions', 'Acknowledgments', 'One-to-one mapping of energy levels to phase shifts in irreps without mixing between $J=1/2$ and $J=3/2$', 'Transformation properties of operators', '\\\\texorpdfstring{Matrices $\\\\mathcalM'])\n",
      "sec='-'\n",
      "lines=[57, 62, 65, 69, 70, 74, 78, 81, 84, 87, 90, 93, 94, 98, 103, 106, 116, 118, 119, 120]\n",
      "sec='author'\n",
      "lines=[58, 63, 66, 71, 75, 79, 82, 85, 88, 91, 95, 99]\n",
      "sec='affiliation'\n",
      "lines=[60, 61, 64, 67, 68, 72, 73, 76, 77, 80, 83, 86, 89, 92, 96, 97, 100, 101, 102]\n",
      "sec='title'\n",
      "lines=[104]\n",
      "sec='date'\n",
      "lines=[105]\n",
      "sec='abstract'\n",
      "lines=[108]\n",
      "sec='Introduction'\n",
      "lines=[123]\n",
      "sec='Gauge Ensemble'\n",
      "lines=[150]\n",
      "KEYWORD: \\end{table} 153\n",
      "Closing KEYWORD: \\end{table} 173\n",
      "sec='Interpolating Operators'\n",
      "lines=[195]\n",
      "KEYWORD: \\end{table*} 198\n",
      "Closing KEYWORD: \\end{table*} 223\n",
      "KEYWORD: \\end{table*} 278\n",
      "Closing KEYWORD: \\end{table*} 323\n",
      "sec='Wick contractions'\n",
      "lines=[400]\n",
      "KEYWORD: \\end{figure} 401\n",
      "Closing KEYWORD: \\end{figure} 410\n",
      "sec='Spectra results'\n",
      "lines=[437]\n",
      "KEYWORD: \\end{figure} 439\n",
      "Closing KEYWORD: \\end{figure} 442\n",
      "KEYWORD: \\end{figure} 445\n",
      "Closing KEYWORD: \\end{figure} 448\n",
      "KEYWORD: \\end{table} 452\n",
      "Closing KEYWORD: \\end{table} 489\n",
      "KEYWORD: \\end{figure*} 492\n",
      "Closing KEYWORD: \\end{figure*} 499\n",
      "KEYWORD: \\end{figure*} 501\n",
      "Closing KEYWORD: \\end{figure*} 507\n",
      "KEYWORD: \\end{figure*} 510\n",
      "Closing KEYWORD: \\end{figure*} 515\n",
      "sec='L{\\\\\"u}scher quantization conditions}\\n'\n",
      "lines=[599]\n",
      "KEYWORD: \\end{table*} 623\n",
      "Closing KEYWORD: \\end{table*} 645\n",
      "sec='Results for the scattering amplitudes'\n",
      "lines=[714]\n",
      "KEYWORD: \\end{table*} 718\n",
      "Closing KEYWORD: \\end{table*} 746\n",
      "sec='Parametrizations used'\n",
      "lines=[752]\n",
      "sec='Fit procedure and results'\n",
      "lines=[781]\n",
      "KEYWORD: \\end{figure*} 783\n",
      "Closing KEYWORD: \\end{figure*} 788\n",
      "KEYWORD: \\end{table*} 792\n",
      "Closing KEYWORD: \\end{table*} 813\n",
      "sec='Conclusions'\n",
      "lines=[893]\n",
      "sec='Acknowledgments'\n",
      "lines=[906]\n",
      "sec='One-to-one mapping of energy levels to phase shifts in irreps without mixing between $J=1/2$ and $J=3/2$'\n",
      "lines=[916]\n",
      "KEYWORD: \\end{table} 921\n",
      "Closing KEYWORD: \\end{table} 948\n",
      "sec='Transformation properties of operators'\n",
      "lines=[953]\n",
      "sec='\\\\texorpdfstring{Matrices $\\\\mathcalM'\n",
      "lines=[991]\n",
      "KEYWORD: \\end{footnotesize} 997\n",
      "Closing KEYWORD: \\end{footnotesize} 1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase too long: 3368  at lines: [203, 205, 210, 212, 214, 216, 219, 221]\n",
      "Splitting phrase in  1  parts\n",
      "Phrase too long: 5290  at lines: [285, 286, 288, 289, 291, 292, 293, 294, 295, 297, 298, 299, 301, 302, 303, 304, 306, 307, 308, 309, 310, 312, 313, 314, 316, 317, 318]\n",
      "Splitting phrase in  1  parts\n",
      "Phrase too long: 3647  at lines: [456, 458, 459, 461, 462, 464, 465, 466, 468, 469, 471, 472, 473, 474, 475, 477, 478, 479, 481, 482, 484, 485]\n",
      "Splitting phrase in  1  parts\n",
      "Phrase too long: 2365  at lines: [601, 602, 608, 609, 614, 618, 621]\n",
      "Splitting phrase in  1  parts\n",
      "Phrase too long: 2089  at lines: [627, 631, 635, 637, 641]\n",
      "Splitting phrase in  1  parts\n",
      "Phrase too long: 4059  at lines: [722, 727, 730, 733, 736, 739, 742]\n",
      "Splitting phrase in  1  parts\n",
      "Phrase too long: 2041  at lines: [798, 799, 800, 801, 804, 806]\n",
      "Splitting phrase in  1  parts\n",
      "Phrase too long: 2446  at lines: [925, 927, 928, 930, 931, 933, 934, 936, 937, 940, 942, 943]\n",
      "Splitting phrase in  1  parts\n",
      "Phrase too long: 8690  at lines: [999, 1008, 1009, 1011, 1021, 1022, 1023, 1026, 1027, 1036, 1039]\n",
      "Splitting phrase in  1  parts\n"
     ]
    }
   ],
   "source": [
    "final_text = embedding_functions.texStripper2(all_tex,'title','abstract') # refine the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for file in final_text.keys():\n",
    "    df = pd.DataFrame(final_text[file]['full'], columns=['Phrase','Lines'])\n",
    "\n",
    "# fix the fact that \\begin{} and end{} should not be asked in SyncTex, Which means when lines start with \n",
    "# \\begin{ or \\end{, they should not be added to the list of lines to be highlighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "# papers/2101.00689/Npi_paper.tex\n",
    "def call_syncTex(dataframe, path_to_pdf, path_to_tex):\n",
    "    \n",
    "    \n",
    "    lines_in_Tex = []\n",
    "    for i in range(len(df)):\n",
    "        collection = []\n",
    "        lines_in_Tex = df.loc[i,'Lines']\n",
    "        gen_dict = {}\n",
    "        \n",
    "        for row in lines_in_Tex:\n",
    "            # print(f\"{row=}\")\n",
    "            result = subprocess.run(['synctex', \n",
    "                                    'view',\n",
    "                                    '-i',f'{row}:0:{path_to_tex}',\n",
    "                                    '-o',f'{path_to_pdf}' ], \n",
    "                                    stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "            # print(result)\n",
    "            \n",
    "            # print(f\"{result=}\")\n",
    "            \n",
    "            for item in result.split('\\n'):\n",
    "                if ':' in item:\n",
    "                    key, value = item.split(':')\n",
    "                    gen_dict[key] = value\n",
    "                    if key=='after':\n",
    "                        # if 228<=gen_dict['TeX_line']<=230:\n",
    "                        collection.append(gen_dict)\n",
    "\n",
    "            \n",
    "            # print(f\"{collection=} {row=}\")\n",
    "        text_instances = set()\n",
    "        for stuck in collection:\n",
    "            if float(stuck['W'])>0:\n",
    "                if float(stuck['y'])<float(stuck['v']):\n",
    "                    text_instances.add((stuck['Page'],\n",
    "                                        float(stuck['h']),\n",
    "                                        # float(stuck['v'])-float(stuck['H']),\n",
    "                                        float(stuck['y'])-9,\n",
    "                                        # max(float(stuck['y'])-9,float(stuck['v'])-float(stuck['H'])),\n",
    "                                        float(stuck['h'])+float(stuck['W']),\n",
    "                                        float(stuck['v']))\n",
    "                                        )\n",
    "                else:\n",
    "                    text_instances.add((stuck['Page'],\n",
    "                                        float(stuck['h']),\n",
    "                                        float(stuck['v'])-9,\n",
    "                                        float(stuck['h'])+float(stuck['W']),\n",
    "                                        float(stuck['v']))\n",
    "                                )\n",
    "        for ii, inst in enumerate(text_instances):\n",
    "            # divide the tuple inst into its components\n",
    "            print(f\"{inst=}\")\n",
    "            (pageNum, x0, y0, x1, y1) = inst \n",
    "            # if it already exists, append pageNum and the 4 coordinates as a list to the dataframe\n",
    "            if df.loc[i,'Page'] != None:\n",
    "                df.loc[i,'Page'].append(pageNum)\n",
    "                df.loc[i,'Highlight'].append(str([x0, y0, x1, y1]))\n",
    "            # if it does not exist, create a new row in the dataframe\n",
    "            else:\n",
    "                df.loc[i,'Page'] = [pageNum]\n",
    "                df.loc[i,'Highlight'] = [str([x0, y0, x1, y1])]\n",
    "    return df\n",
    "\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inst=('1', 71.999985, 333.983795, 539.999985, 355.686157)\n",
      "inst=('1', 71.999985, 333.983795, 539.999985, 355.686157)\n",
      "inst=('1', 71.999985, 333.983795, 539.999985, 355.686157)\n",
      "inst=('1', 71.999985, 351.096344, 539.999985, 366.146942)\n",
      "inst=('1', 71.999985, 376.823181, 539.999985, 387.068481)\n",
      "inst=('1', 71.999985, 417.669952, 539.999985, 429.712555)\n",
      "inst=('1', 71.999985, 459.513062, 539.999985, 470.754669)\n",
      "inst=('1', 71.999985, 598.721375, 297.0336, 611.156921)\n",
      "inst=('1', 314.9664, 536.972595, 540.0000150000001, 548.463257)\n",
      "inst=('1', 314.9664, 676.2901, 540.0000150000001, 687.227295)\n",
      "inst=('2', 71.999985, 141.704834, 297.0336, 152.642014)\n",
      "inst=('2', 71.999985, 350.198517, 297.0336, 360.194794)\n",
      "inst=('2', 71.999985, 486.961243, 297.0336, 497.898407)\n",
      "inst=('2', 382.522552, 166.202759, 428.126926, 177.344772)\n",
      "inst=('2', 314.9664, 218.75354, 540.0000150000001, 229.69072)\n",
      "inst=('2', 314.9664, 356.237946, 540.0000150000001, 367.17511)\n",
      "inst=('2', 314.9664, 379.152039, 540.0000150000001, 390.089203)\n",
      "inst=('2', 314.9664, 413.523132, 540.0000150000001, 424.460297)\n",
      "inst=('2', 314.9664, 470.808319, 540.0000150000001, 482.298981)\n",
      "inst=('2', 314.9664, 563.775635, 540.0000150000001, 575.266296)\n",
      "inst=('3', 71.999985, 513.019653, 297.0336, 523.956848)\n",
      "inst=('3', 71.999985, 547.390747, 297.0336, 558.327942)\n",
      "inst=('3', 71.999985, 571.417297, 297.0336, 582.907959)\n",
      "inst=('3', 71.999985, 571.417297, 297.0336, 582.907959)\n",
      "inst=('3', 71.999985, 641.653931, 297.0336, 651.650146)\n",
      "inst=('3', 135.918915, 666.417175, 160.456764, 677.160645)\n",
      "inst=('3', 71.999985, 711.0, 297.0336, 722.490662)\n",
      "inst=('3', 314.9664, 335.87381, 540.0000150000001, 346.810974)\n",
      "inst=('3', 314.9664, 370.244904, 540.0000150000001, 379.244904)\n",
      "inst=('3', 314.9664, 519.641968, 540.0000150000001, 531.132629)\n",
      "inst=('4', 71.999985, 466.977142, 297.0336, 478.467804)\n",
      "inst=('4', 71.999985, 477.581818, 297.0336, 491.037323)\n",
      "inst=('4', 71.999985, 527.594238, 297.0336, 536.594238)\n",
      "inst=('4', 314.9664, 684.47052, 540.0000150000001, 699.576599)\n",
      "inst=('5', 71.999985, 172.565201, 297.0336, 186.574188)\n",
      "inst=('5', 71.999985, 223.751144, 297.0336, 235.241806)\n",
      "inst=('5', 71.999985, 247.77767899999998, 297.0336, 259.628082)\n",
      "inst=('5', 71.999985, 329.642914, 297.0336, 341.133575)\n",
      "inst=('5', 71.999985, 329.642914, 297.0336, 341.133575)\n",
      "inst=('5', 314.9664, 396.825623, 540.0000150000001, 418.029846)\n",
      "inst=('5', 71.999985, 516.230408, 297.0336, 527.721069)\n",
      "inst=('5', 71.999985, 516.230408, 297.0336, 527.721069)\n",
      "inst=('5', 71.999985, 619.343689, 297.0336, 630.280884)\n",
      "inst=('5', 71.999985, 630.80072, 297.0336, 641.737915)\n",
      "inst=('5', 71.999985, 676.628906, 297.0336, 687.566101)\n",
      "inst=('5', 71.999985, 699.542969, 297.0336, 710.480164)\n",
      "inst=('5', 314.9664, 711.0, 540.0000150000001, 722.490662)\n",
      "inst=('7', 71.999985, 486.562164, 539.999985, 508.264526)\n",
      "inst=('9', 71.999985, 282.276581, 539.999985, 303.978943)\n",
      "inst=('6', 71.999985, 503.94635000000005, 297.0336, 514.883545)\n",
      "inst=('6', 71.999985, 618.367126, 297.0336, 629.857788)\n",
      "inst=('6', 314.9664, 407.825256, 540.0000150000001, 418.181305)\n",
      "inst=('6', 314.9664, 496.126953, 540.0000150000001, 506.123199)\n",
      "inst=('6', 314.9664, 595.189331, 540.0000150000001, 605.9328)\n",
      "inst=('6', 314.9664, 639.218628, 540.0000150000001, 650.70929)\n",
      "inst=('6', 314.9664, 660.384277, 540.0000150000001, 678.304871)\n",
      "inst=('7', 71.999985, 590.792358, 297.0336, 605.34491)\n",
      "inst=('7', 314.9664, 582.950684, 540.0000150000001, 594.441345)\n",
      "inst=('8', 71.999985, 596.429626, 297.0336, 607.366821)\n",
      "inst=('8', 314.9664, 542.60199, 540.0000150000001, 553.539185)\n",
      "inst=('8', 314.9664, 622.925781, 540.0000150000001, 638.004089)\n",
      "inst=('8', 314.9664, 661.556458, 540.0000150000001, 676.634827)\n",
      "inst=('8', 314.9664, 711.0, 540.0000150000001, 722.490662)\n",
      "inst=('9', 71.999985, 347.780914, 297.0336, 359.271576)\n",
      "inst=('9', 71.999985, 396.081879, 297.0336, 405.081909)\n",
      "inst=('9', 71.999985, 428.308167, 297.0336, 439.245331)\n",
      "inst=('10', 71.999985, 227.403717, 297.0336, 244.196594)\n",
      "inst=('10', 71.999985, 550.601501, 297.0336, 561.538696)\n",
      "inst=('10', 71.999985, 575.988403, 297.0336, 585.006226)\n",
      "inst=('10', 71.999985, 688.085938, 297.0336, 699.576599)\n",
      "inst=('10', 71.999985, 711.0, 297.0336, 721.937195)\n",
      "inst=('10', 314.9664, 242.048248, 540.0000150000001, 252.985428)\n",
      "inst=('10', 314.9664, 312.388641, 540.0000150000001, 321.831421)\n",
      "inst=('10', 314.9664, 358.320618, 540.0000150000001, 368.316925)\n",
      "inst=('10', 314.9664, 392.691742, 540.0000150000001, 402.134521)\n",
      "inst=('10', 314.9664, 496.109497, 540.0000150000001, 506.852997)\n",
      "inst=('11', 71.999985, 642.559082, 297.0336, 652.001892)\n",
      "inst=('13', 71.999985, 602.003784, 539.999985, 623.706116)\n",
      "inst=('11', 314.9664, 487.541107, 344.05978400000004, 506.410828)\n",
      "inst=('11', 342.612885, 509.636169, 371.706269, 528.50592)\n",
      "inst=('11', 314.9664, 562.014771, 540.0000150000001, 572.951965)\n",
      "inst=('11', 314.9664, 607.886658, 540.0000150000001, 618.823853)\n",
      "inst=('11', 314.9664, 655.209167, 540.0000150000001, 665.565186)\n",
      "inst=('11', 314.9664, 699.542969, 540.0000150000001, 711.03363)\n",
      "inst=('12', 71.999985, 210.446899, 297.0336, 221.937561)\n",
      "inst=('12', 71.999985, 233.360977, 297.0336, 244.851639)\n",
      "inst=('12', 71.999985, 279.189117, 297.0336, 290.126282)\n",
      "inst=('12', 71.999985, 326.511658, 297.0336, 336.507935)\n",
      "inst=('12', 71.999985, 349.42572, 297.0336, 359.421997)\n",
      "inst=('12', 71.999985, 462.501678, 297.0336, 473.438843)\n",
      "inst=('12', 71.999985, 485.415771, 297.0336, 494.415771)\n",
      "inst=('12', 71.999985, 701.037292, 297.0336, 712.085266)\n",
      "inst=('12', 314.9664, 622.531372, 540.0000150000001, 633.468567)\n",
      "inst=('14', 71.999985, 72.962624, 297.0336, 83.899803)\n",
      "inst=('14', 71.999985, 212.130264, 297.0336, 227.236282)\n",
      "inst=('14', 71.999985, 387.601166, 297.0336, 400.036682)\n",
      "inst=('14', 71.999985, 528.57666, 297.0336, 538.572998)\n",
      "inst=('14', 71.999985, 699.542969, 297.0336, 710.480164)\n",
      "inst=('14', 314.9664, 141.704834, 540.0000150000001, 153.195496)\n",
      "inst=('14', 314.9664, 249.76461799999998, 540.0000150000001, 260.701782)\n",
      "inst=('14', 314.9664, 307.049774, 540.0000150000001, 316.049774)\n",
      "inst=('14', 314.9664, 364.334961, 540.0000150000001, 375.272125)\n",
      "inst=('14', 314.9664, 559.104553, 540.0000150000001, 568.104553)\n",
      "inst=('15', 71.999985, 361.037628, 297.0336, 371.781097)\n",
      "inst=('15', 314.9664, 154.842758, 540.0000150000001, 165.779938)\n",
      "inst=('15', 314.9664, 391.64917, 540.0000150000001, 401.645416)\n",
      "inst=('15', 314.9664, 473.809174, 540.0000150000001, 485.299835)\n",
      "inst=('15', 71.999985, 556.045959, 539.999985, 572.838867)\n"
     ]
    }
   ],
   "source": [
    "df = call_syncTex(df, 'papers/2101.00689/Npi_paper.pdf', 'papers/2101.00689/Npi_paper.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the dataframe and highlight the text\n",
    "doc = fitz.open('papers/2101.00689/Npi_paper.pdf')\n",
    "for i in range(len(df)):\n",
    "    # skip the NaN values\n",
    "    if type(df.loc[i,'Page'])==list:\n",
    "        for j in range(len(df.loc[i,'Page'])):\n",
    "            page = doc[int(df.loc[i,'Page'][j])-1]\n",
    "            rectangle = fitz.Rect(eval(df.loc[i,'Highlight'][j]))\n",
    "            highlight = page.add_highlight_annot(rectangle)\n",
    "            highlight.update()\n",
    "\n",
    "doc.save('papers/2101.00689/Npi_paper_highlighted.pdf', garbage=4, deflate=True, clean=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "doc = fitz.open(\"papers/2101.00689/Npi_paper.pdf\")\n",
    "for page in doc:\n",
    "    ### SEARCH\n",
    "    print(page.number)\n",
    "    \n",
    "    for ii, inst in enumerate(df):\n",
    "        \n",
    "        # divide the tuple inst into its components\n",
    "        (pageNum, x0, y0, x1, y1) = inst \n",
    "        if pageNum==str(page.number+1):\n",
    "            highlight = page.add_highlight_annot(fitz.Rect(x0, y0, x1, y1))\n",
    "            highlight.update()\n",
    "    # for inst in text_instances2:\n",
    "   \n",
    "    #     # divide the tuple inst into its components\n",
    "    #     (pageNum, x0, y0, x1, y1) = inst \n",
    "    #     if pageNum==str(page.number+1):\n",
    "    #         print(inst)\n",
    "    #         highlight = page.add_underline_annot(fitz.Rect(x0, y0, x1, y1))\n",
    "    #         highlight.update()\n",
    "### OUTPUT\n",
    "\n",
    "doc.save(\"output.pdf\", garbage=4, deflate=True, clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131, 132]\n",
      "This is SyncTeX command line utility, version 1.5\n",
      "SyncTeX result begin\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:320.376617\n",
      "y:662.376038\n",
      "h:314.966400\n",
      "v:664.866699\n",
      "W:225.033615\n",
      "H:9.962640\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:321.663513\n",
      "y:616.547913\n",
      "h:314.966400\n",
      "v:619.038574\n",
      "W:225.033615\n",
      "H:9.962640\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:320.501190\n",
      "y:673.833069\n",
      "h:314.966400\n",
      "v:676.323730\n",
      "W:225.033615\n",
      "H:9.962640\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:337.382355\n",
      "y:605.090881\n",
      "h:314.966400\n",
      "v:607.028076\n",
      "W:225.033615\n",
      "H:8.855677\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:340.454193\n",
      "y:650.919006\n",
      "h:314.966400\n",
      "v:653.409668\n",
      "W:225.033615\n",
      "H:9.962640\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:332.124298\n",
      "y:628.004944\n",
      "h:314.966400\n",
      "v:629.942139\n",
      "W:225.033615\n",
      "H:8.855677\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:403.108276\n",
      "y:559.262756\n",
      "h:314.966400\n",
      "v:561.199951\n",
      "W:225.033615\n",
      "H:8.855677\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:345.158783\n",
      "y:570.719788\n",
      "h:314.966400\n",
      "v:572.656982\n",
      "W:225.033615\n",
      "H:8.855677\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:329.107819\n",
      "y:582.176819\n",
      "h:314.966400\n",
      "v:584.114014\n",
      "W:225.033615\n",
      "H:8.855677\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:344.051849\n",
      "y:593.633850\n",
      "h:314.966400\n",
      "v:595.571045\n",
      "W:225.033615\n",
      "H:8.855677\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:341.865540\n",
      "y:639.461975\n",
      "h:314.966400\n",
      "v:641.399170\n",
      "W:225.033615\n",
      "H:8.855677\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:358.691406\n",
      "y:685.290100\n",
      "h:314.966400\n",
      "v:687.227295\n",
      "W:225.033615\n",
      "H:8.855677\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "SyncTeX result end\n",
      "\n",
      "This is SyncTeX command line utility, version 1.5\n",
      "SyncTeX result begin\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:362.621124\n",
      "y:696.747192\n",
      "h:314.966400\n",
      "v:699.237854\n",
      "W:225.033615\n",
      "H:9.962640\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "Output:papers/2101.00689/Npi_paper.pdf\n",
      "Page:1\n",
      "x:391.736908\n",
      "y:685.290100\n",
      "h:314.966400\n",
      "v:687.227295\n",
      "W:225.033615\n",
      "H:8.855677\n",
      "before:\n",
      "offset:-1\n",
      "middle:\n",
      "after:\n",
      "SyncTeX result end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#set the environment variable TOKENIZERS_PARALLELISM=true\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "# extract line 36 from df\n",
    "import subprocess\n",
    "# line_in_df = 15\n",
    "# get all Lines from df\n",
    "lines = []\n",
    "for i in range(len(df)):\n",
    "    lines.extend(df.loc[i,'Lines'])\n",
    "# print(lines)\n",
    "\n",
    "result = ''\n",
    "collection = list()\n",
    "gen_dict = {}\n",
    "\n",
    "line_in_df = 11\n",
    "lines = df.iloc[line_in_df].Lines\n",
    "print(lines)\n",
    "for row in lines:\n",
    "    # print('Row',row)\n",
    "    result = subprocess.run(['synctex', 'view', '-i',f'{row}:0:papers/2101.00689/Npi_paper.tex','-o','papers/2101.00689/Npi_paper.pdf' ], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "    print(result)\n",
    "    for stuck in result.split('\\n'):\n",
    "        \n",
    "        if ':' in stuck:\n",
    "            key, value = stuck.split(':')\n",
    "            gen_dict[key] = value\n",
    "            gen_dict['TeX_line'] = row\n",
    "            if key=='after':\n",
    "                # if 228<=gen_dict['TeX_line']<=230:\n",
    "                collection.append(gen_dict)\n",
    "                gen_dict = {}\n",
    "    \n",
    "import pprint\n",
    "# pprint.pprint(collection)\n",
    "\n",
    "# height from y to v\n",
    "# width from x to h+W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h v represent the beginning of the line x and y\n",
    "# x0<x1 , y0<y1, increase number means go down or right\n",
    "\n",
    "#0._______\n",
    "# |       | \n",
    "# |_______.1\n",
    "\n",
    "\n",
    "### READ IN PDF\n",
    "doc = fitz.open(\"papers/2101.00689/Npi_paper.pdf\")\n",
    "# text_instances = [fitz.Rect(132,489, 296,500)]\n",
    "text_instances = set()\n",
    "text_instances2 = set()\n",
    "\n",
    "for stuck in collection:\n",
    "    #yellow\n",
    "    if float(stuck['W'])>0:\n",
    "        if float(stuck['y'])<float(stuck['v']):\n",
    "            text_instances.add((stuck['Page'],\n",
    "                                float(stuck['h']),\n",
    "                                # float(stuck['v'])-float(stuck['H']),\n",
    "                                float(stuck['y'])-9,\n",
    "                                # max(float(stuck['y'])-9,float(stuck['v'])-float(stuck['H'])),\n",
    "                                float(stuck['h'])+float(stuck['W']),\n",
    "                                float(stuck['v']))\n",
    "                                )\n",
    "        else:\n",
    "            text_instances.add((stuck['Page'],\n",
    "                                float(stuck['h']),\n",
    "                                float(stuck['v'])-9,\n",
    "                                float(stuck['h'])+float(stuck['W']),\n",
    "                                float(stuck['v']))\n",
    "                            )\n",
    "    # #green\n",
    "    # #if float(stuck['y'])<float(stuck['v']):\n",
    "    # text_instances.add((stuck['Page'],\n",
    "    #                         float(stuck['x'])-10,\n",
    "    #                         float(stuck['y'])-10,\n",
    "    #                         float(stuck['x']),\n",
    "    #                         float(stuck['y']),\n",
    "    #                         )\n",
    "    #                         )\n",
    "    # text_instances.add((stuck['Page'],\n",
    "    #                         float(stuck['h']),\n",
    "    #                         float(stuck['v'])-float(stuck['H']),\n",
    "    #                         float(stuck['x']),\n",
    "    #                         float(stuck['v']),\n",
    "    #                         )\n",
    "    #                         )\n",
    "    \n",
    "    ### HIGHLIGHT\n",
    "for page in doc:\n",
    "    ### SEARCH\n",
    "    print(page.number)\n",
    "    \n",
    "    for ii, inst in enumerate(text_instances):\n",
    "        \n",
    "        # divide the tuple inst into its components\n",
    "        (pageNum, x0, y0, x1, y1) = inst \n",
    "        if pageNum==str(page.number+1):\n",
    "            highlight = page.add_highlight_annot(fitz.Rect(x0, y0, x1, y1))\n",
    "            highlight.update()\n",
    "    # for inst in text_instances2:\n",
    "   \n",
    "    #     # divide the tuple inst into its components\n",
    "    #     (pageNum, x0, y0, x1, y1) = inst \n",
    "    #     if pageNum==str(page.number+1):\n",
    "    #         print(inst)\n",
    "    #         highlight = page.add_underline_annot(fitz.Rect(x0, y0, x1, y1))\n",
    "    #         highlight.update()\n",
    "### OUTPUT\n",
    "\n",
    "doc.save(\"output.pdf\", garbage=4, deflate=True, clean=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('PaperOracle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adfda680b332929768398405ffef5c5fca2eb1802e013d485b0c57cfe5351235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
